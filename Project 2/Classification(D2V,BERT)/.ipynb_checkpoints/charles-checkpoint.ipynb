{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\etudiant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from gensim.parsing.preprocessing import stem_text\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "import string\n",
    "import gensim\n",
    "from tqdm.notebook import tqdm   # progress bar\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('x', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "text=\"It's a place for cucks to go and cry that the\\_Donald is down for a little while. Better to not know. Still love you pede. :\\]\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cleanText(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39758c4b0c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Take action: **•** [**Donate**](https://secure.actblue.com/donate/biden-fundraising-dashboard?refcode=reddit) **•** [**Events**](https://www.mobilize.us/joebiden/?source=action-center) **•** [**Register to vote**](https://www.vote.org/) **•** [**Make calls for Joe**](https://joebiden.com/make-calls-for-joe/?source=action-center)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mremove_punct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-3ebc0dd77c33>\u001b[0m in \u001b[0;36mremove_punct\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3ebc0dd77c33>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "text=\"Take action: **•** [**Donate**](https://secure.actblue.com/donate/biden-fundraising-dashboard?refcode=reddit) **•** [**Events**](https://www.mobilize.us/joebiden/?source=action-center) **•** [**Register to vote**](https://www.vote.org/) **•** [**Make calls for Joe**](https://joebiden.com/make-calls-for-joe/?source=action-center)\"\n",
    "remove_punct(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(filename):\n",
    "    sample = open(filename, \"r\",encoding='UTF=8') \n",
    "    sample = sample.readlines() \n",
    "    #biden = biden.replace(\"\\n\", \" \") \n",
    "\n",
    "    sample_all= [] \n",
    "\n",
    "    # iterate through each sentence in the file \n",
    "\n",
    "    for i in sample: \n",
    "        temp = [] \n",
    "        # tokenize the sentence into words \n",
    "        for j in remove_punct(i).split():\n",
    "            if j.isalpha() and j not in stopwords.words('english') and len(j)>1:\n",
    "                temp.append(j.lower()) \n",
    "        twitt=' '.join(temp)\n",
    "        if twitt!='':\n",
    "            sample_all.append(twitt) \n",
    "    return sample_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'!'.isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_train=cleaning(\"JoeBiden_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_train=cleaning(\"The_Donald_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33791"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trump_train)+len(biden_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.DataFrame(data=None,columns=['twitt','relatedTo'])\n",
    "counter=0\n",
    "# Biden=1, Trump=0\n",
    "for biden in biden_train:\n",
    "    train.loc[str(counter)]=[biden, 1]\n",
    "    counter+=1\n",
    "for trump in trump_train:\n",
    "    train.loc[str(counter)]=[trump, 0]\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33791"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.iloc[np.random.permutation(len(train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>relatedTo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11882</th>\n",
       "      <td>as soon hillary running vs bernie changed mind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>personally thats see although believe see what...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10790</th>\n",
       "      <td>hasnt super tuesday already shown us youth vot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18504</th>\n",
       "      <td>the magic gungrabbing biggulprestricting nanny...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25750</th>\n",
       "      <td>if remember correctly nixon roughly votes add ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   twitt relatedTo\n",
       "11882     as soon hillary running vs bernie changed mind         1\n",
       "2061   personally thats see although believe see what...         1\n",
       "10790  hasnt super tuesday already shown us youth vot...         1\n",
       "18504  the magic gungrabbing biggulprestricting nanny...         0\n",
       "25750  if remember correctly nixon roughly votes add ...         0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27a0c3c2970>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby(by='relatedTo').count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving training data\n",
    "train.to_csv('Cleaned_train_TB_WSTW.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_test=cleaning(\"JoeBiden_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the country still getting emotional trauma september th bush still lot builtup goodwill handled iraq starting get dicey public support beginning turn war would continue throughout election year'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_test[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_test=cleaning(\"The_Donald_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank tom'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8864"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trump_test)+len(biden_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame(data=None,columns=['twitt','relatedTo'])\n",
    "counter=0\n",
    "# Biden=1, Trump=0\n",
    "for biden in biden_test:\n",
    "    test.loc[str(counter)]=[biden, 1]\n",
    "    counter+=1\n",
    "for trump in trump_test:\n",
    "    test.loc[str(counter)]=[trump, 0]\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8864"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.iloc[np.random.permutation(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>relatedTo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>got upvote warning message it makes wonder abl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>keep gaslighting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>people dont owe medical records comes disabili...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>you get need</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>would type responses concerns joes website add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  twitt relatedTo\n",
       "7012  got upvote warning message it makes wonder abl...         0\n",
       "184                                    keep gaslighting         1\n",
       "1649  people dont owe medical records comes disabili...         1\n",
       "7682                                       you get need         0\n",
       "378   would type responses concerns joes website add...         1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27a08da1cd0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.groupby(by='relatedTo').count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving test data\n",
    "test.to_csv('Cleaned_test_TB_WSTW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data sets\n",
    "train=pd.read_csv('/Users/charles/Documents/Dossier Python/Jupyter NoteBook/IA/Algo project2/comments/Cleaned_train_TB_WSTW.csv',index_col='no')\n",
    "test=pd.read_csv('/Users/charles/Documents/Dossier Python/Jupyter NoteBook/IA/Algo project2/comments/Cleaned_test_TB_WSTW.csv',index_col='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>relatedTo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11882</th>\n",
       "      <td>as soon hillary running vs bernie changed mind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>personally thats see although believe see what...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10790</th>\n",
       "      <td>hasnt super tuesday already shown us youth vot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18504</th>\n",
       "      <td>the magic gungrabbing biggulprestricting nanny...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25750</th>\n",
       "      <td>if remember correctly nixon roughly votes add ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   twitt  relatedTo\n",
       "no                                                                 \n",
       "11882     as soon hillary running vs bernie changed mind          1\n",
       "2061   personally thats see although believe see what...          1\n",
       "10790  hasnt super tuesday already shown us youth vot...          1\n",
       "18504  the magic gungrabbing biggulprestricting nanny...          0\n",
       "25750  if remember correctly nixon roughly votes add ...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as soon hillary running vs bernie changed mind',\n",
       " 'personally thats see although believe see what see people claiming rhetoric actions regardless personal motivation play interests dubious people',\n",
       " 'hasnt super tuesday already shown us youth voters dont come though',\n",
       " 'the magic gungrabbing biggulprestricting nanny state midget gives run moneyliterally',\n",
       " 'if remember correctly nixon roughly votes add wallaces votes nixon mcgovern way less']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['twitt'].head().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments=[]\n",
    "test_comments=[]\n",
    "for comment in train['twitt'].to_list():\n",
    "    train_comments.append(word_tokenize(comment))\n",
    "for comment in test['twitt'].to_list():\n",
    "    test_comments.append(word_tokenize(comment))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33791"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8864"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DocVec for training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026f0ae8b6ed4e36b5e453bee6dbf157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-428fbbeb2878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     doc_model.train(documents, total_examples=doc_model.corpus_count,\n\u001b[0;32m---> 16\u001b[0;31m                 epochs = 100)\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Iter :: {i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0miterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    551\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    486\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    487\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train docVector\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# PREPARE THE SET OF DOCUMENTS FOR THE MODEL\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_comments)]\n",
    "\n",
    "doc_model = gensim.models.Doc2Vec(vector_size=200, window=3,  compute_loss = True,\n",
    "                               min_count=10, alpha = 0.01)\n",
    "doc_model.build_vocab(documents)\n",
    "\n",
    "# AND TRAIN THE MODEL\n",
    "iterations = tqdm(range(10))\n",
    "for i in iterations:\n",
    "    doc_model.train(documents, total_examples=doc_model.corpus_count,\n",
    "                epochs = 100)\n",
    "    msg = f\"Iter :: {i}\"\n",
    "    iterations.set_postfix_str(s = msg, refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['personally', 'thats', 'see', 'although', 'believe', 'see', 'what', 'see', 'people', 'claiming', 'rhetoric', 'actions', 'regardless', 'personal', 'motivation', 'play', 'interests', 'dubious', 'people'], tags=[1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76067066, -0.63610893, -0.18294784,  2.169702  , -0.02364853,\n",
       "        0.24102147,  0.6327607 ,  0.03598609, -0.67066574, -0.7444184 ,\n",
       "        0.15769787, -1.3969591 ,  0.623509  ,  0.17159429,  0.45973477,\n",
       "        0.3739345 , -0.08032265,  0.28169122, -0.4886401 ,  0.33707702],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = doc_model.docvecs[2]\n",
    "dv[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Savin the model for training\n",
    "doc_model.save('train_DocVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model=Doc2Vec.load('train_DocVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = \"as soon hillary running vs bernie\".split()\n",
    "\n",
    "new_vector = doc_model.infer_vector(tokens)\n",
    "sims = doc_model.docvecs.most_similar([new_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.7842480540275574),\n",
       " (3494, 0.6119270324707031),\n",
       " (11706, 0.6062200665473938),\n",
       " (31767, 0.5784820318222046),\n",
       " (17762, 0.5711911916732788),\n",
       " (320, 0.5626240968704224),\n",
       " (20350, 0.5614511966705322),\n",
       " (28387, 0.5597437620162964),\n",
       " (8313, 0.5594379901885986),\n",
       " (28801, 0.5568548440933228)]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=enumerate(['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [(doc, i) for i, doc in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('b', 1)]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DocVec for test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f580084c4c24687bef4692930cad500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test docVector\n",
    "\n",
    "\n",
    "# PREPARE THE SET OF DOCUMENTS FOR THE MODEL\n",
    "\n",
    "documents_test = [TaggedDocument(doc, [i]) for i, doc in enumerate(test_comments)]\n",
    "\n",
    "doc_model_test = gensim.models.Doc2Vec(vector_size=200, window=3,  compute_loss = True,\n",
    "                               min_count=10, alpha = 0.01)\n",
    "doc_model_test.build_vocab(documents_test)\n",
    "\n",
    "# AND TRAIN THE MODEL\n",
    "iterations = tqdm(range(10))\n",
    "for i in iterations:\n",
    "    doc_model.train(documents_test, total_examples=doc_model_test.corpus_count,\n",
    "                epochs = 100)\n",
    "    msg = f\"Iter :: {i}\"\n",
    "    iterations.set_postfix_str(s = msg, refresh=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model_test.save('test_DocVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model_test=Doc2Vec.load('test_DocVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00047202, -0.00138676,  0.00154257, -0.00083039, -0.0022099 ,\n",
       "        0.00033605, -0.00132483,  0.00100174, -0.00220962, -0.00203468,\n",
       "       -0.00214755,  0.00060172,  0.00175793, -0.00103064,  0.0003842 ,\n",
       "        0.00229315, -0.00032476,  0.0011624 , -0.00138243, -0.00246777],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = doc_model_test.docvecs[2]\n",
    "dv[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data as Panda Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc_model.docvecs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[str(i) for i in range (200)]\n",
    "name=['Related_To']+name\n",
    "train_vec_pd=pd.DataFrame(data=None, index=None, columns=name) \n",
    "# Generating a pd data fram for training DocVectors and the label\n",
    "for i in range(len(train)):\n",
    "    #train_vec_pd.append([train.iloc[i][1]]+list(doc_model.docvecs[i]))\n",
    "    #print(train.iloc[i][1]+list(doc_model.docvecs[i]))\n",
    "    train_vec_pd.loc[str(i)]=[train.iloc[i][1]]+list(doc_model.docvecs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec_pd = train_vec_pd.astype({\"Related_To\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Related_To</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.369257</td>\n",
       "      <td>1.561745</td>\n",
       "      <td>-0.327558</td>\n",
       "      <td>0.363364</td>\n",
       "      <td>-1.073315</td>\n",
       "      <td>1.331756</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>-0.430057</td>\n",
       "      <td>1.641216</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561767</td>\n",
       "      <td>-0.111701</td>\n",
       "      <td>-1.819952</td>\n",
       "      <td>-0.687485</td>\n",
       "      <td>0.420283</td>\n",
       "      <td>-1.228820</td>\n",
       "      <td>0.769485</td>\n",
       "      <td>-0.146520</td>\n",
       "      <td>-0.640254</td>\n",
       "      <td>0.022801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.325083</td>\n",
       "      <td>1.132485</td>\n",
       "      <td>0.386722</td>\n",
       "      <td>-0.806117</td>\n",
       "      <td>0.222724</td>\n",
       "      <td>0.258262</td>\n",
       "      <td>-1.306257</td>\n",
       "      <td>-0.370106</td>\n",
       "      <td>0.298136</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359934</td>\n",
       "      <td>-0.350516</td>\n",
       "      <td>-0.337697</td>\n",
       "      <td>-0.727332</td>\n",
       "      <td>0.685017</td>\n",
       "      <td>-0.298220</td>\n",
       "      <td>0.162071</td>\n",
       "      <td>-1.024459</td>\n",
       "      <td>-1.174072</td>\n",
       "      <td>-0.090377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.130774</td>\n",
       "      <td>-0.539893</td>\n",
       "      <td>-0.026254</td>\n",
       "      <td>2.525591</td>\n",
       "      <td>-0.058954</td>\n",
       "      <td>0.138315</td>\n",
       "      <td>-0.453626</td>\n",
       "      <td>-0.041526</td>\n",
       "      <td>-1.230109</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.738227</td>\n",
       "      <td>1.174132</td>\n",
       "      <td>-0.237114</td>\n",
       "      <td>-1.097397</td>\n",
       "      <td>0.101519</td>\n",
       "      <td>0.754470</td>\n",
       "      <td>0.416478</td>\n",
       "      <td>-1.038084</td>\n",
       "      <td>0.127983</td>\n",
       "      <td>-1.722391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.386716</td>\n",
       "      <td>0.592336</td>\n",
       "      <td>0.254997</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>-0.047023</td>\n",
       "      <td>-0.378955</td>\n",
       "      <td>0.092329</td>\n",
       "      <td>-0.891133</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144276</td>\n",
       "      <td>0.757067</td>\n",
       "      <td>0.136975</td>\n",
       "      <td>-0.233106</td>\n",
       "      <td>1.061653</td>\n",
       "      <td>-0.251082</td>\n",
       "      <td>0.238645</td>\n",
       "      <td>-0.544927</td>\n",
       "      <td>-0.025400</td>\n",
       "      <td>0.346887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.166944</td>\n",
       "      <td>1.137652</td>\n",
       "      <td>-0.462164</td>\n",
       "      <td>0.276122</td>\n",
       "      <td>-0.772688</td>\n",
       "      <td>0.097490</td>\n",
       "      <td>0.873750</td>\n",
       "      <td>-0.678361</td>\n",
       "      <td>-0.871904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950764</td>\n",
       "      <td>0.449472</td>\n",
       "      <td>-0.759913</td>\n",
       "      <td>0.972024</td>\n",
       "      <td>-0.804160</td>\n",
       "      <td>-1.093794</td>\n",
       "      <td>0.371327</td>\n",
       "      <td>0.021101</td>\n",
       "      <td>-0.968555</td>\n",
       "      <td>1.170041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Related_To         0         1         2         3         4         5  \\\n",
       "0           1 -0.369257  1.561745 -0.327558  0.363364 -1.073315  1.331756   \n",
       "1           1  0.325083  1.132485  0.386722 -0.806117  0.222724  0.258262   \n",
       "2           1  1.130774 -0.539893 -0.026254  2.525591 -0.058954  0.138315   \n",
       "3           0 -0.386716  0.592336  0.254997 -0.039923 -0.047023 -0.378955   \n",
       "4           0  0.166944  1.137652 -0.462164  0.276122 -0.772688  0.097490   \n",
       "\n",
       "          6         7         8  ...       190       191       192       193  \\\n",
       "0  0.808982 -0.430057  1.641216  ... -1.561767 -0.111701 -1.819952 -0.687485   \n",
       "1 -1.306257 -0.370106  0.298136  ... -1.359934 -0.350516 -0.337697 -0.727332   \n",
       "2 -0.453626 -0.041526 -1.230109  ... -1.738227  1.174132 -0.237114 -1.097397   \n",
       "3  0.092329 -0.891133  0.041510  ... -0.144276  0.757067  0.136975 -0.233106   \n",
       "4  0.873750 -0.678361 -0.871904  ... -0.950764  0.449472 -0.759913  0.972024   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.420283 -1.228820  0.769485 -0.146520 -0.640254  0.022801  \n",
       "1  0.685017 -0.298220  0.162071 -1.024459 -1.174072 -0.090377  \n",
       "2  0.101519  0.754470  0.416478 -1.038084  0.127983 -1.722391  \n",
       "3  1.061653 -0.251082  0.238645 -0.544927 -0.025400  0.346887  \n",
       "4 -0.804160 -1.093794  0.371327  0.021101 -0.968555  1.170041  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>relatedTo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11882</th>\n",
       "      <td>as soon hillary running vs bernie changed mind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>personally thats see although believe see what...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10790</th>\n",
       "      <td>hasnt super tuesday already shown us youth vot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18504</th>\n",
       "      <td>the magic gungrabbing biggulprestricting nanny...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25750</th>\n",
       "      <td>if remember correctly nixon roughly votes add ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   twitt  relatedTo\n",
       "no                                                                 \n",
       "11882     as soon hillary running vs bernie changed mind          1\n",
       "2061   personally thats see although believe see what...          1\n",
       "10790  hasnt super tuesday already shown us youth vot...          1\n",
       "18504  the magic gungrabbing biggulprestricting nanny...          0\n",
       "25750  if remember correctly nixon roughly votes add ...          0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec_pd.to_csv('train_vec_pd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[str(i) for i in range (200)]\n",
    "name=['Related_To']+name\n",
    "test_vec_pd=pd.DataFrame(data=None, index=None, columns=name) \n",
    "# Generating a pd data fram for training DocVectors and the label\n",
    "for i in range(len(test)):\n",
    "    #train_vec_pd.append([train.iloc[i][1]]+list(doc_model.docvecs[i]))\n",
    "    #print(train.iloc[i][1]+list(doc_model.docvecs[i]))\n",
    "    test_vec_pd.loc[str(i)]=[int(test.iloc[i][1])]+list(doc_model_test.docvecs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_pd = test_vec_pd.astype({\"Related_To\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Related_To</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>-0.000853</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.002066</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-0.000583</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>-0.002049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>-0.001232</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.001240</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>-0.001387</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001625</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>-0.002062</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>-0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>-0.002260</td>\n",
       "      <td>-0.001423</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Related_To         0         1         2         3         4         5  \\\n",
       "0           0  0.001508  0.002077 -0.000044 -0.000770 -0.000803 -0.000346   \n",
       "1           1 -0.002471 -0.002326  0.002044 -0.000118 -0.000980 -0.001442   \n",
       "2           1  0.000472 -0.001387  0.001543 -0.000830 -0.002210  0.000336   \n",
       "3           0  0.001429 -0.001671  0.001611 -0.000335 -0.001102  0.002398   \n",
       "4           1  0.001477 -0.000339 -0.002384  0.001334 -0.001142  0.000055   \n",
       "\n",
       "          6         7         8  ...       190       191       192       193  \\\n",
       "0  0.002117 -0.001785  0.000598  ...  0.001685  0.002410 -0.000853 -0.002383   \n",
       "1 -0.000936 -0.001232  0.000192  ...  0.001093  0.002189 -0.001618 -0.001240   \n",
       "2 -0.001325  0.001002 -0.002210  ... -0.001625  0.002392  0.001915  0.000177   \n",
       "3  0.000549  0.001153  0.000483  ...  0.002483 -0.000555 -0.000901  0.001774   \n",
       "4 -0.000711  0.002088 -0.000910  ...  0.000659 -0.001902  0.001964  0.001653   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.001453 -0.002066  0.000423 -0.000583  0.002118 -0.002049  \n",
       "1  0.000178  0.000997  0.001717 -0.000549 -0.000745 -0.000492  \n",
       "2  0.001820 -0.000327 -0.000549 -0.002062  0.001514 -0.000670  \n",
       "3  0.001016  0.000158  0.002297 -0.001709 -0.000658  0.001703  \n",
       "4  0.001146 -0.002260 -0.001423 -0.000613 -0.000658  0.002152  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>relatedTo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>got upvote warning message it makes wonder abl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>keep gaslighting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>people dont owe medical records comes disabili...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>you get need</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>would type responses concerns joes website add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  twitt  relatedTo\n",
       "no                                                                \n",
       "7012  got upvote warning message it makes wonder abl...          0\n",
       "184                                    keep gaslighting          1\n",
       "1649  people dont owe medical records comes disabili...          1\n",
       "7682                                       you get need          0\n",
       "378   would type responses concerns joes website add...          1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_pd.to_csv('test_vec_pd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To free up space we remove all necessary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train)\n",
    "del(test)\n",
    "del(doc_model)\n",
    "del(doc_model_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train_vec_pd)\n",
    "del(test_vec_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the operations above were performed to obtain a DocVector data set. So, if you have the data sets, you do not need to run the above cells. Just upload the finalized the datasets. Note that we upload the data sets into train and test panda data frames. Do not get confused with these names that are used in the previous cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('/Users/charles/Documents/Dossier Python/Jupyter NoteBook/IA/Algo project2/comments/train_vec_pd.csv',index_col='no')\n",
    "test=pd.read_csv('/Users/charles/Downloads/test_vec_pd (1).csv',index_col='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Related_To']=train['Related_To']\n",
    "test['Related_To']=test['Related_To'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Related_To</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.026599</td>\n",
       "      <td>0.581778</td>\n",
       "      <td>-0.532914</td>\n",
       "      <td>0.394876</td>\n",
       "      <td>-1.345078</td>\n",
       "      <td>0.537034</td>\n",
       "      <td>0.467228</td>\n",
       "      <td>-0.707096</td>\n",
       "      <td>1.020035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.880489</td>\n",
       "      <td>-0.293891</td>\n",
       "      <td>-0.571775</td>\n",
       "      <td>-0.420658</td>\n",
       "      <td>0.057390</td>\n",
       "      <td>-0.416865</td>\n",
       "      <td>0.560844</td>\n",
       "      <td>-0.831045</td>\n",
       "      <td>-0.461474</td>\n",
       "      <td>0.566579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>-0.019412</td>\n",
       "      <td>0.065919</td>\n",
       "      <td>0.077867</td>\n",
       "      <td>-0.079864</td>\n",
       "      <td>-0.049173</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>0.051727</td>\n",
       "      <td>-0.065801</td>\n",
       "      <td>0.044094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>-0.100437</td>\n",
       "      <td>-0.036695</td>\n",
       "      <td>0.077505</td>\n",
       "      <td>-0.028776</td>\n",
       "      <td>-0.071083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.518383</td>\n",
       "      <td>0.414897</td>\n",
       "      <td>0.566892</td>\n",
       "      <td>0.472283</td>\n",
       "      <td>-0.003099</td>\n",
       "      <td>0.137265</td>\n",
       "      <td>-0.657649</td>\n",
       "      <td>0.104781</td>\n",
       "      <td>-0.310656</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.373075</td>\n",
       "      <td>0.226707</td>\n",
       "      <td>-0.180812</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>-0.542115</td>\n",
       "      <td>0.283669</td>\n",
       "      <td>0.167111</td>\n",
       "      <td>-0.219647</td>\n",
       "      <td>0.898659</td>\n",
       "      <td>-0.296231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>-0.261489</td>\n",
       "      <td>0.289496</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>0.105046</td>\n",
       "      <td>-0.127548</td>\n",
       "      <td>-0.078861</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>-0.062827</td>\n",
       "      <td>0.106777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>0.080585</td>\n",
       "      <td>-0.063326</td>\n",
       "      <td>-0.112808</td>\n",
       "      <td>0.143099</td>\n",
       "      <td>-0.027229</td>\n",
       "      <td>-0.075236</td>\n",
       "      <td>-0.181759</td>\n",
       "      <td>-0.188027</td>\n",
       "      <td>-0.023233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>-0.200038</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.557780</td>\n",
       "      <td>0.838453</td>\n",
       "      <td>-0.264646</td>\n",
       "      <td>0.356070</td>\n",
       "      <td>-0.433429</td>\n",
       "      <td>-0.701314</td>\n",
       "      <td>0.972814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907007</td>\n",
       "      <td>-0.228191</td>\n",
       "      <td>-0.485627</td>\n",
       "      <td>0.499191</td>\n",
       "      <td>-0.618351</td>\n",
       "      <td>-0.169992</td>\n",
       "      <td>0.128020</td>\n",
       "      <td>-0.494776</td>\n",
       "      <td>0.146727</td>\n",
       "      <td>-0.084760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Related_To         0         1         2         3         4         5  \\\n",
       "no                                                                           \n",
       "0        False -0.026599  0.581778 -0.532914  0.394876 -1.345078  0.537034   \n",
       "1         True -0.019412  0.065919  0.077867 -0.079864 -0.049173 -0.003414   \n",
       "2         True  0.518383  0.414897  0.566892  0.472283 -0.003099  0.137265   \n",
       "3        False -0.261489  0.289496  0.046429  0.105046 -0.127548 -0.078861   \n",
       "4         True -0.200038  0.391813  0.557780  0.838453 -0.264646  0.356070   \n",
       "\n",
       "           6         7         8  ...       190       191       192       193  \\\n",
       "no                                ...                                           \n",
       "0   0.467228 -0.707096  1.020035  ... -0.880489 -0.293891 -0.571775 -0.420658   \n",
       "1   0.051727 -0.065801  0.044094  ...  0.015450  0.025906  0.002022  0.000268   \n",
       "2  -0.657649  0.104781 -0.310656  ... -1.373075  0.226707 -0.180812  0.026565   \n",
       "3   0.035524 -0.062827  0.106777  ... -0.007292  0.080585 -0.063326 -0.112808   \n",
       "4  -0.433429 -0.701314  0.972814  ... -0.907007 -0.228191 -0.485627  0.499191   \n",
       "\n",
       "         194       195       196       197       198       199  \n",
       "no                                                              \n",
       "0   0.057390 -0.416865  0.560844 -0.831045 -0.461474  0.566579  \n",
       "1   0.005076 -0.100437 -0.036695  0.077505 -0.028776 -0.071083  \n",
       "2  -0.542115  0.283669  0.167111 -0.219647  0.898659 -0.296231  \n",
       "3   0.143099 -0.027229 -0.075236 -0.181759 -0.188027 -0.023233  \n",
       "4  -0.618351 -0.169992  0.128020 -0.494776  0.146727 -0.084760  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.iloc[:,1:200].to_numpy().astype('int')\n",
    "Y_train=train.iloc[:,0].to_numpy()\n",
    "X_test=test.iloc[:,1:200].to_numpy()\n",
    "Y_test=test.iloc[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim= 199, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_loss = tf.keras.losses.CosineSimilarity()\n",
    "l = tf.keras.losses.LogCosh()\n",
    "h = tf.keras.losses.Huber()\n",
    "b = 'binary_crossentropy'\n",
    "poisson = tf.keras.losses.Poisson\n",
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "KLD = tf.keras.losses.KLDivergence(reduction=\"auto\", name=\"kl_divergence\")\n",
    "\n",
    "model.compile(loss=l , optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 [==============================] - 0s 752us/step - loss: 0.1231 - accuracy: 0.5003\n",
      "Epoch 1/8\n",
      "   2/6759 [..............................] - ETA: 3:13 - loss: 0.1264 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0561s). Check your callbacks.\n",
      "6759/6759 [==============================] - 9s 1ms/step - loss: 0.1007 - accuracy: 0.6549 - val_loss: 0.0929 - val_accuracy: 0.6831\n",
      "Epoch 2/8\n",
      "6759/6759 [==============================] - 9s 1ms/step - loss: 0.0976 - accuracy: 0.6662 - val_loss: 0.0879 - val_accuracy: 0.6930\n",
      "Epoch 3/8\n",
      "6759/6759 [==============================] - 8s 1ms/step - loss: 0.0958 - accuracy: 0.6735 - val_loss: 0.0886 - val_accuracy: 0.7018\n",
      "Epoch 4/8\n",
      "6759/6759 [==============================] - 8s 1ms/step - loss: 0.0942 - accuracy: 0.6807 - val_loss: 0.0877 - val_accuracy: 0.7044\n",
      "Epoch 5/8\n",
      "6759/6759 [==============================] - 8s 1ms/step - loss: 0.0928 - accuracy: 0.6858 - val_loss: 0.0892 - val_accuracy: 0.6984\n",
      "Epoch 6/8\n",
      "6759/6759 [==============================] - 9s 1ms/step - loss: 0.0918 - accuracy: 0.6923 - val_loss: 0.0918 - val_accuracy: 0.6957\n",
      "Epoch 7/8\n",
      "6759/6759 [==============================] - 8s 1ms/step - loss: 0.0911 - accuracy: 0.6963 - val_loss: 0.0894 - val_accuracy: 0.6983\n",
      "Epoch 8/8\n",
      "6759/6759 [==============================] - 8s 1ms/step - loss: 0.0901 - accuracy: 0.7007 - val_loss: 0.0912 - val_accuracy: 0.6939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a58189f50>"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/CatCross_10_2_5_sig\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "model.evaluate(X_test, Y_test)\n",
    "model.fit(X_train, Y_train, epochs=8, batch_size=5,callbacks=[tensorboard_callback], validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 [==============================] - 0s 675us/step - loss: 0.1232 - accuracy: 0.5093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12324832379817963, 0.5092508792877197]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8a62fae3fc983f5b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8a62fae3fc983f5b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "scaler = StandardScaler()  # doctest: +SKIP\n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  # doctest: +SKIP\n",
    "X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method evaluate in module tensorflow.python.keras.engine.training:\n",
      "\n",
      "evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False) method of tensorflow.python.keras.engine.sequential.Sequential instance\n",
      "    Returns the loss value & metrics values for the model in test mode.\n",
      "    \n",
      "    Computation is done in batches (see the `batch_size` arg.)\n",
      "    \n",
      "    Arguments:\n",
      "        x: Input data. It could be:\n",
      "          - A Numpy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "          - A TensorFlow tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "          - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "          - A `tf.data` dataset. Should return a tuple\n",
      "            of either `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      "            or `(inputs, targets, sample_weights)`.\n",
      "          A more detailed description of unpacking behavior for iterator types\n",
      "          (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      "          for iterator-like inputs` section of `Model.fit`.\n",
      "        y: Target data. Like the input data `x`, it could be either Numpy\n",
      "          array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      "          (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      "          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      "          should not be specified (since targets will be obtained from the\n",
      "          iterator/dataset).\n",
      "        batch_size: Integer or `None`. Number of samples per batch of\n",
      "          computation. If unspecified, `batch_size` will default to 32. Do not\n",
      "          specify the `batch_size` if your data is in the form of a dataset,\n",
      "          generators, or `keras.utils.Sequence` instances (since they generate\n",
      "          batches).\n",
      "        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      "        sample_weight: Optional Numpy array of weights for the test samples,\n",
      "          used for weighting the loss function. You can either pass a flat (1D)\n",
      "          Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples), or in the case of\n",
      "              temporal data, you can pass a 2D array with shape `(samples,\n",
      "              sequence_length)`, to apply a different weight to every timestep\n",
      "              of every sample. This argument is not supported when `x` is a\n",
      "              dataset, instead pass sample weights as the third element of `x`.\n",
      "        steps: Integer or `None`. Total number of steps (batches of samples)\n",
      "          before declaring the evaluation round finished. Ignored with the\n",
      "          default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      "          None, 'evaluate' will run until the dataset is exhausted. This\n",
      "          argument is not supported with array inputs.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      "          callbacks to apply during evaluation. See\n",
      "          [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "          input only. Maximum size for the generator queue. If unspecified,\n",
      "          `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "          only. Maximum number of processes to spin up when using process-based\n",
      "          threading. If unspecified, `workers` will default to 1. If 0, will\n",
      "          execute the generator on the main thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "          `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "          threading. If unspecified, `use_multiprocessing` will default to\n",
      "          `False`. Note that because this implementation relies on\n",
      "          multiprocessing, you should not pass non-picklable arguments to the\n",
      "          generator as they can't be passed easily to children processes.\n",
      "        return_dict: If `True`, loss and metric results are returned as a dict,\n",
      "          with each key being the name of the metric. If `False`, they are\n",
      "          returned as a list.\n",
      "    \n",
      "    See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      "    `Model.fit`.\n",
      "    \n",
      "    Returns:\n",
      "        Scalar test loss (if the model has a single output and no metrics)\n",
      "        or list of scalars (if the model has multiple outputs\n",
      "        and/or metrics). The attribute `model.metrics_names` will give you\n",
      "        the display labels for the scalar outputs.\n",
      "    \n",
      "    Raises:\n",
      "        RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      "        ValueError: in case of invalid arguments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analysis: Finding the best perameter (the number of components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=-88.532):\n",
      "{'n_components': 45}\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "pca = PCA()\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'n_components': [5, 15, 30, 45, 64,96,128]\n",
    "}\n",
    "search = GridSearchCV(pca, param_grid, n_jobs=-1)\n",
    "search.fit(X_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple Logistic regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 678 ms, sys: 26.8 ms, total: 705 ms\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(random_state=0,solver='saga').fit(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5279783393501805"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_Train=LR.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.61      0.63     16460\n",
      "        True       0.66      0.70      0.67     17331\n",
      "\n",
      "    accuracy                           0.66     33791\n",
      "   macro avg       0.66      0.65      0.65     33791\n",
      "weighted avg       0.66      0.66      0.66     33791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_train,pre_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      4432\n",
      "        True       0.50      1.00      0.67      4432\n",
      "\n",
      "    accuracy                           0.50      8864\n",
      "   macro avg       0.25      0.50      0.33      8864\n",
      "weighted avg       0.25      0.50      0.33      8864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy Score is 0.5\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy Score is ' + str(metrics.accuracy_score(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model acts poorly on the test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLPClassifier in module sklearn.neural_network._multilayer_perceptron:\n",
      "\n",
      "class MLPClassifier(sklearn.base.ClassifierMixin, BaseMultilayerPerceptron)\n",
      " |  MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate at each\n",
      " |        time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : double, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : double, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : boolean, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for\n",
      " |      ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      " |      except in a multilabel setting.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      " |      The solver iterates until convergence (determined by 'tol'), number\n",
      " |      of iterations reaches max_iter, or this number of loss function calls.\n",
      " |      Note that number of loss function calls will be greater than or equal\n",
      " |      to the number of iterations for the `MLPClassifier`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  coefs_ : list, length n_layers - 1\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list, length n_layers - 1\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_iter_ : int,\n",
      " |      The number of iterations the solver has ran.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : string\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_classification(n_samples=100, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      " |  >>> clf.predict_proba(X_test[:1])\n",
      " |  array([[0.038..., 0.961...]])\n",
      " |  >>> clf.predict(X_test[:5, :])\n",
      " |  array([1, 0, 1, 0, 1])\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.8...\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to log(predict_proba(X))\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  partial_fit\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array, shape (n_classes), default None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(200, 30),\n",
       "              random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', activation='logistic' , alpha=1e-05,  hidden_layer_sizes=(200,30) , random_state=1)\n",
    "\n",
    "clf.fit(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011281588447654"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_Train=clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy Score is 0.5045130360155071\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy Score is ' + str(metrics.accuracy_score(Y_train,pre_Train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.90      0.65     16460\n",
      "        True       0.66      0.18      0.28     17331\n",
      "\n",
      "    accuracy                           0.53     33791\n",
      "   macro avg       0.58      0.54      0.47     33791\n",
      "weighted avg       0.58      0.53      0.46     33791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_train,pre_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.91      0.65      4432\n",
      "           1       0.52      0.10      0.17      4432\n",
      "\n",
      "    accuracy                           0.50      8864\n",
      "   macro avg       0.51      0.50      0.41      8864\n",
      "weighted avg       0.51      0.50      0.41      8864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy Score is 0.5038357400722022\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy Score is ' + str(metrics.accuracy_score(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54674556, 0.5315182 , 0.55844925, 0.58064516, 0.58182894,\n",
       "       0.58952353, 0.581533  , 0.59100326, 0.58301273, 0.58745191])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "cross_val_score(clf, X_train, Y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49548696398449293"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_test, Y_test)\n",
    "clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: GridSearch to find best parameters for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rf = RandomForestClassifier().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16460\n",
      "           1       1.00      1.00      1.00     17331\n",
      "\n",
      "    accuracy                           1.00     33791\n",
      "   macro avg       1.00      1.00      1.00     33791\n",
      "weighted avg       1.00      1.00      1.00     33791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_Train=Rf.predict(X_train)\n",
    "print(metrics.classification_report(Y_train,pre_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=Rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59      4432\n",
      "           1       0.51      0.31      0.38      4432\n",
      "\n",
      "    accuracy                           0.51      8864\n",
      "   macro avg       0.51      0.51      0.49      8864\n",
      "weighted avg       0.51      0.51      0.49      8864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy Score is 0.5069945848375451\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy Score is ' + str(metrics.accuracy_score(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "n=[i+1 for i in range(25)]\n",
    "mfeat=['auto', 'log2', None]\n",
    "param={'n_estimators':n, \"max_features\": mfeat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 375 out of 375 | elapsed: 52.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_features': ['auto', 'log2', None],\n",
       "                         'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                          22, 23, 24, 25]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid=GridSearchCV(estimator=rf,param_grid=param, scoring='accuracy', n_jobs=-1, verbose=3,cv=5)\n",
    "rf_grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': None, 'n_estimators': 25}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55      4432\n",
      "           1       0.50      0.39      0.44      4432\n",
      "\n",
      "    accuracy                           0.50      8864\n",
      "   macro avg       0.50      0.50      0.50      8864\n",
      "weighted avg       0.50      0.50      0.50      8864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy Score is 0.5011281588447654\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy Score is ' + str(metrics.accuracy_score(Y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=32)\n",
    "pca.fit(X_test)\n",
    "\n",
    "TrainingX = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=32)\n",
    "pca.fit(X_test)\n",
    "\n",
    "testX = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.29 s, sys: 76.4 ms, total: 1.37 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(random_state=0,solver='saga').fit(TrainingX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(TrainingX, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_Train=LR.predict(TrainingX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70     16460\n",
      "           1       0.72      0.68      0.70     17331\n",
      "\n",
      "    accuracy                           0.70     33791\n",
      "   macro avg       0.70      0.70      0.70     33791\n",
      "weighted avg       0.70      0.70      0.70     33791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_train,pre_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=LR.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4432\n",
      "           1       0.50      1.00      0.67      4432\n",
      "\n",
      "    accuracy                           0.50      8864\n",
      "   macro avg       0.25      0.50      0.33      8864\n",
      "weighted avg       0.25      0.50      0.33      8864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8864"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33791, 8864]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-224d6b6e3599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preciosion on training set\\n '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \"\"\"\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33791, 8864]"
     ]
    }
   ],
   "source": [
    "print('Preciosion on training set\\n ' +metrics.classification_report(Y_train,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision on test set\\n ' +metrics.classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And alternative approach: tagging the docs with their relations to the US Presidential candidates then find the most similar sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('Cleaned_train_TB_WSTW.csv',index_col='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments_tagged=[]\n",
    "\n",
    "for i in range(len(train)):\n",
    "    twitt=word_tokenize(train.iloc[i,0])\n",
    "    train_comments_tagged.append((twitt,train.iloc[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['as', 'soon', 'hillary', 'running', 'vs', 'bernie', 'changed', 'mind'], 1)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comments_tagged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train docVector\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# PREPARE THE SET OF DOCUMENTS FOR THE MODEL\n",
    "documents = [TaggedDocument(doc, [i]) for doc,i in train_comments_tagged]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['help', 'us'], tags=[0])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9826279f51b24804b53f76e884bbe3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_train_tagged = gensim.models.Doc2Vec(vector_size=200, window=3,  compute_loss = True,\n",
    "                               min_count=10, alpha = 0.01)\n",
    "doc_train_tagged.build_vocab(documents)\n",
    "\n",
    "# AND TRAIN THE MODEL\n",
    "iterations = tqdm(range(10))\n",
    "for i in iterations:\n",
    "    doc_train_tagged.train(documents, total_examples=doc_train_tagged.corpus_count,\n",
    "                epochs = 100)\n",
    "    msg = f\"Iter :: {i}\"\n",
    "    iterations.set_postfix_str(s = msg, refresh=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Trining another doc2vector. It gives us worst model\n",
    "doc_train_tagged = gensim.models.Doc2Vec(vector_size=300, window=5,  compute_loss = True,\n",
    "                               min_count=5, alpha = 0.01)\n",
    "doc_train_tagged.build_vocab(documents)\n",
    "\n",
    "# AND TRAIN THE MODEL\n",
    "iterations = tqdm(range(10))\n",
    "for i in iterations:\n",
    "    doc_train_tagged.train(documents, total_examples=doc_train_tagged.corpus_count,\n",
    "                epochs = 100)\n",
    "    msg = f\"Iter :: {i}\"\n",
    "    iterations.set_postfix_str(s = msg, refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Savin the model for training\n",
    "doc_train_tagged.save('train_DocVec_tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_train_tagged=Doc2Vec.load('train_DocVec_tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = \"if remember correctly nixon roughly votes add\".split()\n",
    "\n",
    "new_vector = doc_train_tagged.infer_vector(tokens)\n",
    "sims = doc_train_tagged.docvecs.most_similar([new_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.6073166728019714), (1, 0.5847710371017456)]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Strategy: Just the most Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Similar(g_model,twitt):\n",
    "    tokens = twitt.split()\n",
    "\n",
    "    new_vector = g_model.infer_vector(tokens)\n",
    "    sims = g_model.docvecs.most_similar([new_vector])\n",
    "    return sims[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('Cleaned_test_TB_WSTW.csv',index_col='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6986687725631769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "success=0\n",
    "biden=[]\n",
    "trump=[]\n",
    "matrix={1:{1:0,0:0},0:{1:0,0:0}}\n",
    "for i in range(len(test)):\n",
    "    twitt=test.iloc[i,0]\n",
    "    predicted=predict_Similar(doc_train_tagged,twitt)\n",
    "    matrix[test.iloc[i,1]][predicted]+=1\n",
    "    if predicted==test.iloc[i,1]:\n",
    "        success+=1\n",
    "print('Accuracy: ' + str(success/len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {1: 2712, 0: 1720}, 0: {1: 955, 0: 3477}}"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4432"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list(matrix[0].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weighted Strategy: polling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model=Doc2Vec.load('train_DocVec')\n",
    "train=pd.read_csv('Cleaned_train_TB_WSTW.csv',index_col='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>relatedTo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11882</th>\n",
       "      <td>as soon hillary running vs bernie changed mind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>personally thats see although believe see what...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10790</th>\n",
       "      <td>hasnt super tuesday already shown us youth vot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18504</th>\n",
       "      <td>the magic gungrabbing biggulprestricting nanny...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25750</th>\n",
       "      <td>if remember correctly nixon roughly votes add ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   twitt  relatedTo\n",
       "no                                                                 \n",
       "11882     as soon hillary running vs bernie changed mind          1\n",
       "2061   personally thats see although believe see what...          1\n",
       "10790  hasnt super tuesday already shown us youth vot...          1\n",
       "18504  the magic gungrabbing biggulprestricting nanny...          0\n",
       "25750  if remember correctly nixon roughly votes add ...          0"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Similar_weighted(g_model,twitt,selection):\n",
    "    tokens = twitt.split()\n",
    "\n",
    "    new_vector = g_model.infer_vector(tokens)\n",
    "    sims = g_model.docvecs.most_similar([new_vector])\n",
    "    total=0\n",
    "    total=np.sum([b for (a,b) in sims[:selection]])\n",
    "    weight=0\n",
    "    for i in sims[:selection]:\n",
    "        weight+=(i[1]/total) * train.iloc[i[0],1]\n",
    "    return int(np.round(weight))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_Similar_weighted(doc_model,\"if remember correctly nixon roughly vote\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for weighted method: 0.6432761732851986\n"
     ]
    }
   ],
   "source": [
    "success=0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    twitt=test.iloc[i,0]\n",
    "    predicted=predict_Similar_weighted(doc_model,twitt,5)\n",
    "    if predicted==test.iloc[i,1]:\n",
    "        success+=1\n",
    "print('Accuracy for weighted method: ' + str(success/len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the above model on dataset with stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SW=pd.read_csv('Cleaned_train_TB.csv',index_col='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments_tagged_SW=[]\n",
    "\n",
    "for i in range(len(train_SW)):\n",
    "    twitt=word_tokenize(train_SW.iloc[i,0])\n",
    "    train_comments_tagged_SW.append((twitt,train_SW.iloc[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train docVector\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# PREPARE THE SET OF DOCUMENTS FOR THE MODEL\n",
    "documents = [TaggedDocument(doc, [i]) for doc,i in train_comments_tagged_SW]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['was', 'it', 'was', 'i', 'was', 'near', 'the', 'green', 'new', 'deal', 'people', 'the', 'ones', 'that', 'knocked', 'symone', 'to', 'the'], tags=[1])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d4691cfe324714932b8b0eb2450534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_train_tagged_SW = gensim.models.Doc2Vec(vector_size=200, window=3,  compute_loss = True,\n",
    "                               min_count=10, alpha = 0.025,min_alpha=0.025)\n",
    "doc_train_tagged_SW.build_vocab(documents)\n",
    "\n",
    "# AND TRAIN THE MODEL\n",
    "iterations = tqdm(range(10))\n",
    "for i in iterations:\n",
    "    doc_train_tagged_SW.train(documents, total_examples=doc_train_tagged_SW.corpus_count,\n",
    "                epochs = 100)\n",
    "    doc_train_tagged_SW.alpha -= 0.002  # decrease the learning rate\n",
    "    doc_train_tagged_SW.min_alpha = doc_train_tagged_SW.alpha  # fix the learning rate, no decay\n",
    "    msg = f\"Iter :: {i}\"\n",
    "    iterations.set_postfix_str(s = msg, refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Savin the model for training\n",
    "doc_train_tagged.save('train_DocVec_tagged_SW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_train_tagged_SW=Doc2Vec.load('train_DocVec_tagged_SW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('Cleaned_test_TB.csv',index_col='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6369645042839658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "success=0\n",
    "biden=[]\n",
    "trump=[]\n",
    "matrix={1:{1:0,0:0},0:{1:0,0:0}}\n",
    "for i in range(len(test)):\n",
    "    twitt=test.iloc[i,0]\n",
    "    predicted=predict_Similar(doc_train_tagged_SW,twitt)\n",
    "    matrix[test.iloc[i,1]][predicted]+=1\n",
    "    if predicted==test.iloc[i,1]:\n",
    "        success+=1\n",
    "print('Accuracy: ' + str(success/len(test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
